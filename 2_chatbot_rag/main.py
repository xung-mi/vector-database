import time
from models.llm_loader import load_llm
from models.embedding_loader import load_embeddings
from pipeline.web_scraper import process_website
from pipeline.rag_chain import build_rag_chain

def main():
    print("ğŸŒ Nháº­p URL website cáº§n xá»­ lÃ½:")
    url = input("â†’ URL: ")
    print("ğŸ”„ Äang phÃ¢n tÃ­ch website...")
    docs = process_website(url)
    
    print("ğŸ“¥ Äang táº£i LLM vÃ  Embedding...")
    llm = load_llm()
    embeddings = load_embeddings()

    print("ğŸ§  XÃ¢y dá»±ng RAG pipeline...")
    qa_chain, vectorstore = build_rag_chain(llm, docs, embeddings)

    print("âœ… Há»‡ thá»‘ng sáºµn sÃ ng. Há»i gÃ¬ cÅ©ng Ä‘Æ°á»£c (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t)")
    while True:
        query = input("ğŸ—£ï¸ Báº¡n: ")
        if query.strip().lower() == "exit":
            break
        
        
        start_time = time.time()
        result = qa_chain.invoke({"query": query})
        answer = result['result']
        end_time = time.time()

        elapsed = end_time - start_time
        print(f"ğŸ¤– Bot: {answer}")
        print(f"â±ï¸ Thá»i gian pháº£n há»“i: {elapsed:.2f} giÃ¢y\n")
        

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ÄÃ£ dá»«ng chatbot. Táº¡m biá»‡t!")