import requests
from bs4 import BeautifulSoup
from langchain_community.document_loaders import BSHTMLLoader
from langchain.text_splitter import CharacterTextSplitter
import tempfile, os
from config import CHUNK_SIZE, CHUNK_OVERLAP

def fetch_html(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    return response.text


def process_website(url):
    html_content = fetch_html(url)
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.html') as temp:
        temp.write(html_content)
        path = temp.name

    loader = BSHTMLLoader(path)
    documents = loader.load()
    os.remove(path)

    splitter = CharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    chunks = splitter.split_documents(documents)

    print(f"\nğŸ” Sá»‘ Ä‘oáº¡n vÄƒn báº£n sau khi chia: {len(chunks)}")
    print("ğŸ“ Ná»™i dung máº«u Ä‘Ã£ load (tá»‘i Ä‘a 5 Ä‘oáº¡n Ä‘áº§u):\n")
    for i, doc in enumerate(chunks[:5]):
        print(f"[{i+1}] {doc.page_content[:500]}...\n")  # Giá»›i háº¡n 500 kÃ½ tá»±

    return chunks
