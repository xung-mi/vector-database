# ===============================================================
# âœ… EMBEDDING PIPELINE TOÃ€N TRÃŒNH: CHUNKING + LOCAL EMBEDDING + CHROMA
# ===============================================================
# âœ”ï¸ Chunking Documents with overlap
# âœ”ï¸ Local model for embedding (e.g. SimCSE, MiniLM)
# âœ”ï¸ Embedding tá»«ng chunk â†’ gÃ¡n vÃ o doc.embedding
# âœ”ï¸ Insert vÃ o ChromaDB (persistent)
# âœ”ï¸ CÃ³ thá»ƒ kiá»ƒm tra báº±ng SQLite DB viewer
# ===============================================================

import os
import uuid
from typing import List
from chromadb.config import Settings
import chromadb
from sentence_transformers import SentenceTransformer

# ===============================================================
# 1. Cáº¤U HÃŒNH MODEL EMBEDDING LOCAL
# ---------------------------------------------------------------
# Äáº£m báº£o Ä‘Ã£ táº£i sáºµn model vá» local
model_path = "local_models/all-MiniLM-L6-v2"
model = SentenceTransformer(model_path)

# ===============================================================
# 2. CLASS DOCUMENT Äá»‚ GÃN TEXT, ID, CHUNK & EMBEDDING
# ---------------------------------------------------------------
class DocumentChunk:
    def __init__(self, chunk_id: str, content: str, source_doc: str):
        self.id = chunk_id
        self.text = content
        self.source = source_doc
        self.embedding = None  # sáº½ Ä‘Æ°á»£c gÃ¡n sau

# ===============================================================
# 3. CHUNKING FUNCTION
# ---------------------------------------------------------------
def split_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 100) -> List[str]:
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        chunks.append(text[start:end])
        start += chunk_size - chunk_overlap
    return chunks

# ===============================================================
# 4. Táº O EMBEDDING CHO 1 CHUNK TEXT
# ---------------------------------------------------------------
def get_local_embedding(text: str) -> List[float]:
    return model.encode(text).tolist()

# ===============================================================
# 5. LOAD VÃ€ CHUNK TOÃ€N Bá»˜ DOCUMENTS
# ---------------------------------------------------------------
def load_and_chunk_documents(folder_path: str) -> List[DocumentChunk]:
    all_chunks = []
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            file_path = os.path.join(folder_path, filename)
            with open(file_path, "r", encoding="utf-8") as f:
                raw_text = f.read()
                chunks = split_text(raw_text, chunk_size=1000, chunk_overlap=100)
                for i, chunk in enumerate(chunks):
                    chunk_id = str(uuid.uuid4())
                    doc = DocumentChunk(chunk_id, chunk, filename)
                    all_chunks.append(doc)
    print(f"ğŸ“„ Tá»•ng cá»™ng {len(all_chunks)} chunks Ä‘Ã£ Ä‘Æ°á»£c táº¡o tá»« {folder_path}")
    return all_chunks

# ===============================================================
# 6. INSERT CHUNKS VÃ€O CHROMA DB
# ---------------------------------------------------------------
def insert_chunks_into_chroma(chunks: List[DocumentChunk], db_dir: str = "DB"):
    chroma_client = chromadb.Client(Settings(persist_directory=db_dir))
    collection = chroma_client.get_or_create_collection(name="document_QA_collection")

    print("ğŸ§  Äang táº¡o embeddings cho cÃ¡c chunks...")
    for chunk in chunks:
        chunk.embedding = get_local_embedding(chunk.text)

    print("ğŸ’¾ Äang insert vÃ o ChromaDB...")
    collection.upsert(
        documents=[c.text for c in chunks],
        embeddings=[c.embedding for c in chunks],
        metadatas=[{"source": c.source} for c in chunks],
        ids=[c.id for c in chunks]
    )

    print(f"âœ… ÄÃ£ lÆ°u {len(chunks)} chunk vÃ o ChromaDB.")

# ===============================================================
# 7. CHáº Y TOÃ€N Bá»˜ PIPELINE
# ---------------------------------------------------------------
def run_pipeline():
    folder_path = "documents"
    if not os.path.exists(folder_path):
        raise FileNotFoundError("âŒ Folder 'documents' khÃ´ng tá»“n táº¡i!")

    print("ğŸš€ Báº¯t Ä‘áº§u pipeline: Load â†’ Chunk â†’ Embed â†’ Insert...")
    chunks = load_and_chunk_documents(folder_path)
    insert_chunks_into_chroma(chunks)
    print("ğŸ‰ Pipeline hoÃ n táº¥t!")

# ===============================================================
# CHáº Y
# ===============================================================
if __name__ == "__main__":
    run_pipeline()
