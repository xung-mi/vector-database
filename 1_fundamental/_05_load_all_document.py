# ===============================================================
# âœ… XÃ‚Y Dá»°NG VECTOR STORE Vá»šI LOCAL EMBEDDING + CHROMADB PERSISTENT
# ---------------------------------------------------------------
# 1. Äá»c nhiá»u file .txt tá»« thÆ° má»¥c
# 2. TÃ¡ch chunk cÃ³ overlap
# 3. DÃ¹ng mÃ´ hÃ¬nh LOCAL embedding (sentence-transformers)
# 4. LÆ°u vÃ o ChromaDB persistent
# ===============================================================

import os
import uuid
from typing import List
from chromadb.config import Settings
import chromadb
from sentence_transformers import SentenceTransformer

# ===============================================================
# 1. Cáº¤U HÃŒNH MODEL EMBEDDING LOCAL
# ---------------------------------------------------------------
# Báº¡n cáº§n Ä‘áº£m báº£o Ä‘Ã£ táº£i trÆ°á»›c model vá» local (vÃ­ dá»¥: local_models/...)

# Tiáº¿ng Anh (nháº¹): all-MiniLM-L6-v2
# model_path = "local_models/all-MiniLM-L6-v2"

# Hoáº·c dÃ¹ng tiáº¿ng Viá»‡t máº¡nh hÆ¡n:
model_path = "local_models/SimCSE-VietNamese-phobert"

print(f"ğŸ”„ Äang táº£i mÃ´ hÃ¬nh tá»« local: {model_path}")
embedding_model = SentenceTransformer(model_path)

# ===============================================================
# 2. LOAD Táº¤T Cáº¢ FILE .txt TRONG THÆ¯ Má»¤C
# ---------------------------------------------------------------
def load_documents_from_directory(folder_path: str) -> List[dict]:
    documents = []
    for filename in os.listdir(folder_path):
        if filename.endswith(".txt"):
            file_path = os.path.join(folder_path, filename)
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
                documents.append({
                    "id": filename,
                    "text": text
                })
    print(f"ğŸ“„ ÄÃ£ load {len(documents)} documents tá»« thÆ° má»¥c {folder_path}")
    return documents

# ===============================================================
# 3. CHUNK TEXT Vá»šI OVERLAP
# ---------------------------------------------------------------
def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 20) -> List[str]:
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + chunk_size, len(text))
        chunks.append(text[start:end])
        start += chunk_size - overlap
    return chunks

# ===============================================================
# 4. Táº O EMBEDDINGS Vá»šI MÃ” HÃŒNH LOCAL
# ---------------------------------------------------------------
def get_embeddings(texts: List[str]) -> List[List[float]]:
    return embedding_model.encode(texts).tolist()

# ===============================================================
# 5. KHá»I Táº O CHROMA Vá»šI PERSISTENT FOLDER
# ---------------------------------------------------------------
db_dir = "DB"  # Folder lÆ°u trá»¯ dá»¯ liá»‡u
client_chroma = chromadb.Client(Settings(persist_directory=db_dir))
collection = client_chroma.get_or_create_collection(name="document_QA_collection")

# ===============================================================
# 6. QUY TRÃŒNH Xá»¬ LÃ HOÃ€N CHá»ˆNH
# ---------------------------------------------------------------
folder_path = "documents"  # ThÆ° má»¥c chá»©a cÃ¡c file .txt

all_docs = load_documents_from_directory(folder_path)
all_chunks = []
chunk_metadatas = []

print("ğŸ”§ Äang chunk vÄƒn báº£n vá»›i overlap...")

for doc in all_docs:
    chunks = chunk_text(doc["text"], chunk_size=1000, overlap=20)
    for i, chunk in enumerate(chunks):
        all_chunks.append(chunk)
        chunk_metadatas.append({
            "source_doc": doc["id"],
            "chunk_id": i
        })

print(f"ğŸ§© ÄÃ£ táº¡o tá»•ng cá»™ng {len(all_chunks)} chunks tá»« {len(all_docs)} documents.")

# ===============================================================
# 7. Táº O EMBEDDINGS & LÆ¯U VÃ€O CHROMADB
# ---------------------------------------------------------------
print("ğŸ§  Äang táº¡o vector embedding vá»›i mÃ´ hÃ¬nh local...")
embeddings = get_embeddings(all_chunks)

chunk_ids = [str(uuid.uuid4()) for _ in all_chunks]

print("ğŸ’¾ Äang lÆ°u dá»¯ liá»‡u vÃ o ChromaDB (persistent)...")
collection.add(
    documents=all_chunks,
    ids=chunk_ids,
    embeddings=embeddings,
    metadatas=chunk_metadatas
)

print("âœ… ÄÃ£ lÆ°u vector vÃ o collection 'document_QA_collection' trong folder DB.")

# ===============================================================
# 8. VALIDATION
# ---------------------------------------------------------------
print("\nğŸ“Š Validation:")
print(f"Sá»‘ lÆ°á»£ng documents gá»‘c: {len(all_docs)} (expect: 21)")
print(f"Sá»‘ chunks Ä‘Ã£ xá»­ lÃ½: {len(all_chunks)}")

print("\nğŸ“Œ VÃ­ dá»¥ chunk Ä‘áº§u:")
print("Nguá»“n:", chunk_metadatas[0])
print("VÄƒn báº£n:", all_chunks[0][:200], "...")
